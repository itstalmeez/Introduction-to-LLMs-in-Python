# Introduction to LLMs in Python

This repository contains my work from the "Introduction to LLMs in Python" course on DataCamp. The course introduces various topics related to Large Language Models (LLMs) using the Hugging Face `transformers` library.

## What I’ve Learned So Far

### 1. **Text Generation**:
   - Using models like `distilgpt2` for generating text based on a prompt.
   
### 2. **Language Translation**:
   - Implementing text translation from English to Spanish using pre-trained models.

### 3. **Exploring Different Model Types**:
   - **Encoder-only models** (e.g., BERT)
   - **Decoder-only models** (e.g., GPT)
   - **Encoder-decoder models** (e.g., Helsinki)

### 4. **Dataset Handling**:
   - Loading datasets like IMDB and preparing them for fine-tuning.
   - Tokenization of datasets using `AutoTokenizer`.

### 5. **Model Fine-tuning**:
   - Fine-tuning models for classification tasks with custom datasets.

### 6. **Saving and Loading Fine-tuned Models**:
   - Saving models and tokenizers for later use.

## Next Steps
In the upcoming part of the course, I plan to dive deeper into training models and exploring more advanced topics in LLMs.

## Installation

To run the code, you’ll need to install the following libraries:

```bash
pip install transformers datasets torch
